{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANLY 677 Final Project\n",
    "### Clare Garberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ9bgGL8b8-0"
   },
   "source": [
    "# Fine Grained Analysis with ResNet152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otYt9OT9f_4z"
   },
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3yo4dO04nsW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import PIL\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15ysTVFBMWXJ"
   },
   "source": [
    "## Data Preprocessing  \n",
    "- Downloading and extracting custom datasets  \n",
    "- Loading custom datasets  \n",
    "- Calculating the mean and std for normalization on custom datasets  \n",
    "- Loading transforms to augment and normalize our data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Make sure to drop grayscale images or any other odd images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tollaAJNCN7"
   },
   "outputs": [],
   "source": [
    "root = \"/Users/claregarberg/Documents/Graduate School/Summer 2022/Image Analytics/ANLY677_FinalProject_v2\"\n",
    "\n",
    "os.chdir(root)\n",
    "\n",
    "train_path = \"/Users/claregarberg/Documents/Graduate School/Summer 2022/Image Analytics/ANLY677_FinalProject_v2/train_data\"\n",
    "\n",
    "test_path = \"/Users/claregarberg/Documents/Graduate School/Summer 2022/Image Analytics/ANLY677_FinalProject_v2/test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0lgPnAeMWXL"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.transforms import CenterCrop\n",
    "\n",
    "\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        max_wh = max(image.size)\n",
    "        p_left, p_top = [(max_wh - s) // 2 for s in image.size]\n",
    "        p_right, p_bottom = [max_wh - (s+pad) for s, pad in zip(image.size, [p_left, p_top])]\n",
    "        padding = (p_left, p_top, p_right, p_bottom)\n",
    "        return torchvision.transforms.functional.pad(image, padding, 0, 'constant')\n",
    "\n",
    "\n",
    "mean = [0.5683, 0.5578, 0.5178]\n",
    "std = [0.2378, 0.2437, 0.2670]\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "      SquarePad(),\n",
    "      torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "      torchvision.transforms.RandomVerticalFlip(p = 0.5),\n",
    "      torchvision.transforms.Resize(224),\n",
    "      #torchvision.transforms.CenterCrop(224),\n",
    "      #torchvision.transforms.RandomResizedCrop(224, (0.8, 1.0)),\n",
    "      torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize(\n",
    "          mean=mean,\n",
    "          std=std\n",
    "          )\n",
    "    ]\n",
    ")\n",
    "\n",
    "train = torchvision.datasets.ImageFolder(\n",
    "    root = train_path,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, \n",
    "    batch_size= 64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test = torchvision.datasets.ImageFolder(\n",
    "    root = test_path,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test, \n",
    "    batch_size= 64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "wEEwNOMbUT0X",
    "outputId": "526a629d-2dbd-4456-97cc-4f05625dbbaa"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4,figsize= (15,15))\n",
    "\n",
    "for i in range(16):\n",
    "\n",
    "  img = train[i][0].numpy().transpose(1, 2, 0)\n",
    "  img = np.clip((std * img) + mean, 0, 1)\n",
    "  axes.flat[i].imshow(img)\n",
    "  axes.flat[i].set_title(str(train[i][1]))\n",
    "\n",
    "# Follow aspect ratio of either 1:1 or 1.68:1 (8.5, 4.75/5)\n",
    "#fig.savefig('/Users/claregarberg/Documents/Graduate School/Summer 2022/Image Analytics/ANLY677_FinalProject_v2/train_image_transformations_Project.jpg', dpi=300, bbox_inches='tight')  \n",
    "#fig.savefig('/Users/claregarberg/Documents/Graduate School/Summer 2022/Image Analytics/ANLY677_FinalProject_v2/train_image_transformations_Project.png', dpi=300, bbox_inches='tight')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZGU2tiCupMU"
   },
   "source": [
    "### Define Model(ResNet152)\n",
    "**We will use first 7 layers of ResNet152 model and add 2 custom FC linear layer with batch normalization as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADWfnK_8uoop"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        resnet = torchvision.models.resnet152(weights='ResNet152_Weights.DEFAULT')\n",
    "        # freezing parameters\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # convolutional layers of resnet152\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.top_model = nn.Sequential(*layers)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 15)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.top_model(x))\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1) # flattening \n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cuda = False    \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  cuda = True\n",
    "\n",
    "ResNet_152 = Net()\n",
    "\n",
    "if cuda:\n",
    "  ResNet_152.cuda()\n",
    "\n",
    "print(ResNet_152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC4_kYphvM16"
   },
   "source": [
    "### Optimizer\n",
    "We will use **Adam** as our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params = ResNet_152.parameters(),   lr= 1e-3, momentum= 0.9 )\n",
    "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj_riya9wjJI"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbzMjx6qchwD"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tqdm as tqdm\n",
    "\n",
    "EPOCHS = 50  # 50\n",
    "\n",
    "train_loss = [np.nan]\n",
    "train_accuracy = [np.nan]\n",
    "test_loss = [np.nan]\n",
    "\n",
    "ResNet_152.train()\n",
    "\n",
    "pbar = tqdm.tqdm(total=EPOCHS, position=0, leave=True)\n",
    "pbar.set_description(\"EPOCH 1: Training Loss: NA, \")\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  total, correct, running_loss = 0, 0, 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    ResNet_152.train()\n",
    "    if cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = ResNet_152(data)\n",
    "\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss.cpu().data.item()\n",
    "    running_loss += current_loss\n",
    "\n",
    "    _, predicted = out.max(1)\n",
    "    total += target.size(0)\n",
    "    correct += predicted.eq(target).sum().cpu().item()\n",
    "\n",
    "    pbar.set_description(f\"EPOCH {epoch+1}\\t Batch Loss: {current_loss:.3f}\\t  Epoch Loss: {train_loss[-1]:.3f}\\t Train Acc: {train_accuracy[-1]:.3f}\\t Test Loss: {test_loss[-1]:.3f}\\t\")\n",
    "\n",
    "  test_running_loss = 0\n",
    "  ResNet_152.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      if cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "      out = ResNet_152(data)\n",
    "\n",
    "      loss = criterion(out, target)\n",
    "\n",
    "      test_running_loss += loss.cpu().data.item()\n",
    "\n",
    "    LTest = test_running_loss/len(test_loader)\n",
    "\n",
    "  LTrain = running_loss/len(train_loader)\n",
    "  accu = 100.*correct/total\n",
    "\n",
    "  train_accuracy.append(accu)\n",
    "  train_loss.append(LTrain)\n",
    "  test_loss.append(LTest)\n",
    "\n",
    "  pbar.set_description(\n",
    "      f\"EPOCH {epoch+1}\\t Batch Loss: {current_loss:.3f}\\t  Epoch Loss: {train_loss[-1]:.3f}\\t Train Acc: {train_accuracy[-1]:.3f}\\t Test Loss: {test_loss[-1]:.3f}\\t\")\n",
    "\n",
    "  pbar.update()\n",
    "\n",
    "del train_accuracy[0]\n",
    "del train_loss[0]\n",
    "del test_loss[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1a8F2fAwnD6"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uxax9FQOUArF"
   },
   "outputs": [],
   "source": [
    "def save_model(m, p):\n",
    "    torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p):\n",
    "    m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"model1_tmp.pth\"\n",
    "save_model(ResNet_152, str(p))\n",
    "load_model(ResNet_152, str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncq2BRRY6OnD"
   },
   "source": [
    "### Unfreeze the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTMT-wgAq12"
   },
   "outputs": [],
   "source": [
    "def set_trainable_attr(m, b=True):\n",
    "    for p in m.parameters(): p.requires_grad = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4yOOzuONFvj"
   },
   "outputs": [],
   "source": [
    "def unfreeze(model, l):\n",
    "    top_model = model.top_model\n",
    "    set_trainable_attr(top_model[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o86FKdOqNMuJ"
   },
   "outputs": [],
   "source": [
    "unfreeze(ResNet_152, 7)\n",
    "unfreeze(ResNet_152, 6)\n",
    "unfreeze(ResNet_152, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnljpp-UZ-96"
   },
   "source": [
    "### Unfreezing few more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6ChL9kzO2VO"
   },
   "outputs": [],
   "source": [
    "load_model(ResNet_152, str(p))\n",
    "unfreeze(ResNet_152, 4)\n",
    "unfreeze(ResNet_152, 3)\n",
    "unfreeze(ResNet_152, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "gd_5Rpq4fIlM",
    "outputId": "e56b1386-f7c9-4301-d353-574470fb1096"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tqdm as tqdm\n",
    "\n",
    "EPOCHS = 50  # 50\n",
    "\n",
    "train_loss = [np.nan]\n",
    "train_accuracy = [np.nan]\n",
    "test_loss = [np.nan]\n",
    "\n",
    "ResNet_152.train()\n",
    "\n",
    "pbar = tqdm.tqdm(total=EPOCHS, position=0, leave=True)\n",
    "pbar.set_description(\"EPOCH 1: Training Loss: NA, \")\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  total, correct, running_loss = 0, 0, 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    ResNet_152.train()\n",
    "    if cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = ResNet_152(data)\n",
    "\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss.cpu().data.item()\n",
    "    running_loss += current_loss\n",
    "\n",
    "    _, predicted = out.max(1)\n",
    "    total += target.size(0)\n",
    "    correct += predicted.eq(target).sum().cpu().item()\n",
    "\n",
    "    pbar.set_description(f\"EPOCH {epoch+1}\\t Batch Loss: {current_loss:.3f}\\t  Epoch Loss: {train_loss[-1]:.3f}\\t Train Acc: {train_accuracy[-1]:.3f}\\t Test Loss: {test_loss[-1]:.3f}\\t\")\n",
    "\n",
    "  test_running_loss = 0\n",
    "  ResNet_152.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      if cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "      out = ResNet_152(data)\n",
    "\n",
    "      loss = criterion(out, target)\n",
    "\n",
    "      test_running_loss += loss.cpu().data.item()\n",
    "\n",
    "    LTest = test_running_loss/len(test_loader)\n",
    "\n",
    "  LTrain = running_loss/len(train_loader)\n",
    "  accu = 100.*correct/total\n",
    "\n",
    "  train_accuracy.append(accu)\n",
    "  train_loss.append(LTrain)\n",
    "  test_loss.append(LTest)\n",
    "\n",
    "  pbar.set_description(\n",
    "      f\"EPOCH {epoch+1}\\t Batch Loss: {current_loss:.3f}\\t  Epoch Loss: {train_loss[-1]:.3f}\\t Train Acc: {train_accuracy[-1]:.3f}\\t Test Loss: {test_loss[-1]:.3f}\\t\")\n",
    "\n",
    "  pbar.update()\n",
    "\n",
    "del train_accuracy[0]\n",
    "del train_loss[0]\n",
    "del test_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lab 8\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import RcParams\n",
    "\n",
    "\n",
    "myrcparams = RcParams({'axes.axisbelow': True,\n",
    "          'axes.edgecolor': 'white',\n",
    "          'axes.facecolor': '#EAEAF2',\n",
    "          'axes.grid': True,\n",
    "          'axes.labelcolor': '.15',\n",
    "          'axes.linewidth': 0.0,\n",
    "          'figure.facecolor': 'white',\n",
    "          'font.family': ['serif'],\n",
    "          'grid.color': 'white',\n",
    "          'grid.linestyle': '--',\n",
    "          'image.cmap': 'Greys',\n",
    "          'legend.frameon': False,\n",
    "          'legend.numpoints': 1,\n",
    "          'legend.scatterpoints': 1,\n",
    "          'lines.solid_capstyle': 'round',\n",
    "          'text.color': '.15',\n",
    "          'xtick.color': '.15',\n",
    "          'xtick.direction': 'out',\n",
    "          'xtick.major.size': 0.0,\n",
    "          'xtick.minor.size': 0.0,\n",
    "          'ytick.color': '.15',\n",
    "          'ytick.direction': 'out',\n",
    "          'ytick.major.size': 0.0,\n",
    "          'ytick.minor.size': 0.0})\n",
    "\n",
    "plt.style.library['seaborn-whitegrid']\n",
    "RcParams.update(myrcparams)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(8.5,5), dpi=300)\n",
    "\n",
    "x = np.arange(1,len(train_loss)+1)\n",
    "\n",
    "ax.plot(x, train_loss, '-o', label = \"Train Loss\", linewidth = 1.5)\n",
    "ax.plot(x, test_loss, '-o', label = \"Test Loss\", linewidth = 1.5)\n",
    "\n",
    "ax.set_xlabel(\"Epochs\", fontsize = 24)\n",
    "ax.set_ylabel(\"Loss\", fontsize = 24)\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'both',\n",
    "    labelsize = 16\n",
    ")\n",
    "ax.legend(fontsize = 20)\n",
    "ax.set_title(\"Loss vs Epochs\", fontsize = 24, fontweight = 'bold')\n",
    "\n",
    "plt.savefig(\"Loss vs Epochs_ResNet152.jpg\", dpi = 300, bbox_inches = 'tight')\n",
    "plt.savefig(\"Loss vs Epochs_ResNet152.pdf\", dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = x.tolist()\n",
    "\n",
    "df = pd.DataFrame(list(zip(x_list, train_loss, test_loss)), columns =['Epoch', 'Train_Loss', \"Test_Loss\"])\n",
    "\n",
    "df.to_csv('ResNet152_Loss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXP5h6N7ZpZ6"
   },
   "source": [
    "## Accuracy Metrics:\n",
    "The code below is dervied from Pytorch github [code](https://github.com/pytorch/examples/blob/master/imagenet/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JilTC6BeYLf7"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aT0rCehtYjqo"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    #with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WRZpAU_Ymf5"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    #model.cuda()    \n",
    "    \n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    for idx, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        inputs, labels = inputs.cpu().float(), labels.cpu().long()\n",
    "        # obtain the outputs from the model\n",
    "        outputs = model.forward(inputs)\n",
    "        prec1, prec5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        top5.update(prec5[0], inputs.size(0))\n",
    "        \n",
    "    return top1.avg.cpu().detach().numpy(), top5.avg.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtTTubEMYqoU"
   },
   "outputs": [],
   "source": [
    "top1_accuracy, top5_accuracy = calc_accuracy(ResNet_152, test_loader)\n",
    "print('top1 accuracy{: .2f}%, top5 accuracy{: .2f}%\\n'.format(top1_accuracy, top5_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating confusion matrix\n",
    "idx_to_class = inv_map = {v: k for k, v in test.class_to_idx.items()}\n",
    "\n",
    "correct = []\n",
    "pred = []\n",
    "\n",
    "ResNet_152.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data,target) in enumerate(test_loader):\n",
    "        if cuda:\n",
    "          data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        out = ResNet_152(data)\n",
    "\n",
    "\n",
    "        for _,i in enumerate(out):\n",
    "\n",
    "            pred.append(torch.argmax(i).cpu().item())\n",
    "            correct.append(target[_].cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_pred= pred, y_true = correct)\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (15,15))\n",
    "plt.title('ResNet152 Confusion Matrix', fontsize = 28)\n",
    "ax.set_xlabel('Predicted labels', fontsize = 24)\n",
    "ax.set_ylabel('True labels', fontsize = 24)\n",
    "plt.imshow(conf, interpolation='none', cmap = 'Blues')\n",
    "\n",
    "fig.savefig(\"ResNet152_CM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"ResNet152_CM.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CUB-200_ResNet34.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
